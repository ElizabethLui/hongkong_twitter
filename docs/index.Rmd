---
title: "Hong Kong Tweets Analysis"
output: html_document
---

```{r include=FALSE}
library(quanteda)
library(qlcMatrix)
library(stringdist)
library(vars)
library(AER)
library(readxl)
library(stargazer)
library(scales)
library(quantmod)
library(urca)
library(sandwich)
library(lmtest)
library(forecast)
library(dyn)
library(rtweet) ; library(tidyverse) ; library(tidytext)
library(twitteR)
library(igraph)
library(stringr)
library(tidygraph)
library(ggraph)
library(stringi)
library(tidyr)
library(xts)
library(DescTools)
library(ggplot2)  # For graphics
library(dplyr)  # For aggregating
library(stringr)
library(wordcloud)
library(gdata)
library(dynlm)
library(ggthemes)

```




### Load the 3 datasets as dataframes ###
```{r}
df <- read.csv('tweets_all.csv') #hk tweets
us <-read.csv('us.csv') #hk tweets from us politicians
uk <-read.csv('uk.csv') #hk tweets from uk politicians
```


### Visualize the frequency of tweets by day ###
```{r warning=FALSE}

df$created_at <- as.Date(df$created_at) #first, change "created_at" as date item

options(scipen=999) #avoid scientific notation on graph

tweet_count <-  ts_plot(df, by = "days") + 
                  labs(x = NULL, y = NULL,
                  title = "Frequency of Tweets by Day") +
                theme_wsj(base_size = 8)

plot(tweet_count)
```


###Visualize the tweets from UK & US politicians that responded to the protests in Hong Kong ####

```{r warning=FALSE}
#combime us & uk datadrame using the library "gdata"
elite <- combine(us, uk)

#change column name from "source" to "country"

names(elite)[names(elite) == "source"] <- "Country" 

#plot ts for elite response
elite_count <-elite %>%
    dplyr::group_by(Country) %>%
    ts_plot("days") +
    labs(x = NULL, y = NULL,
       title = "Foreign Politicians' Tweets") +
  theme_wsj(base_size = 8)

plot(elite_count)
```


### Find the most mentioned accounts ###

```{r warning=FALSE}
#first, extract all mentions from tweets
df$mentions <- str_extract_all(df$text, "@\\w+") 

#remove @ in mention
df$mentions <- str_remove_all(df$mentions, "@")

mention_count <- df %>% 
  count(mentions, sort = TRUE) %>%
  top_n(20)

mention_count <- mention_count[mention_count$mentions!='character(0)',] #remove empty mentions

mention_plot <-ggplot(mention_count, aes(y = mentions, x = n)) + 
  geom_bar(stat="identity") +
  ggtitle("Most Mentioned Accounts") +
  labs(y="Twitter Accounts", x = "No. of Times Mentioned") + 
  theme_wsj(base_size = 8)

plot(mention_plot)
```


### Find the most used hashtags ###
```{r warning=FALSE}
#extract hashtags & save as new column in df
df$hashtags <- str_extract_all(df$text, "#\\w+")

#remove # in hashtags
df$hashtags <- str_remove_all(df$hashtags, "#")

#remove empty hashtags
df_hash <- df[df$hashtags!='character(0)',]

hash_count <- df_hash %>% 
  count(hashtags, sort = TRUE) %>%
  top_n(10)

hash_plot <-ggplot(hash_count, aes(y = hashtags, x = n)) + 
  geom_bar(stat="identity") +
  ggtitle("Most Used Hashtags") +
  labs(y="Hashtags", x = "No. of Times Used") + 
  theme_wsj(base_size = 8)

plot(hash_plot)


```
